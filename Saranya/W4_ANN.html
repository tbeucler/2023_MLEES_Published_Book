

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5.1. Introduction to Artificial Neural Networks &#8212; Machine Learning for Earth and Environmental Sciences</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Saranya/W4_ANN';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5.2. (Exercise) Artificial Neural Networks with Keras" href="../DL/S4_1_NNs_with_Keras.html" />
    <link rel="prev" title="5. Artificial Neural Networks and Surrogate Modeling" href="../DL/Week_4_Artificial_Neural_Networks.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Welcome to Machine Learning for Earth and Environmental Sciences
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Milton/00_Running_Python_Scripts.html">Running Python scripts</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">(Part I) Basics of Scientific Programming for Applied Machine Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../IP/intro_python.html">1. Introduction to Python for Earth and Environmental Sciences</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../IP/W1_S1_Tutorial.html">1.1. Variables, Control Flow, and File I/O</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W1_S1.html">1.2. (Exercises) Text and Tabular Files</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W1_S2_Tutorial.html">1.3. Data Structure, Functions, and Classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W1_S2.html">1.4. (Exercises) Simple Data Structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W2_S1_Tutorial.html">1.5. Scientific Computing with Numpy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W2_S1.html">1.6. (Exercise) Ocean Floats Data Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W2_S2_Tutorial.html">1.7. Visualization with Matplotlib and Cartopy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W2_S2.html">1.8. (Exercises) Replicating plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W3_S1_Tutorial.html">1.9. Tabular Data with Pandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W3_S1.html">1.10. (Exercise) Earthquake Data Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W3_S2_Tutorial.html">1.11. Geospatial Data with Geopandas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W3_S2.html">1.12. (Exercise) Hurricane Track Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W4_S1_Tutorial.html">1.13. Regression, Classification, and Clustering with Scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W4_S1.html">1.14. (Exercises) Multivariate linear regression and clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W4_S2_Tutorial.html">1.15. Statistical Graphics with Seaborn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../IP/W4_S2.html">1.16. (Exercise) Marathon Data Analysis</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">(Part II) Basics of Machine Learning for Earth and Environmental Sciences</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../ML/Week_1_Linear%26Logistic_Regression.html">2. Linear Regression for Regression, Logistic Regression for Classification and Statistical Forecasting</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="W1_2.html">2.1. Classification and Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ML/S1_1_Classification.html">2.2. (Exercises) Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ML/S1_2_Training_Models.html">2.3. (Exercises) Training Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="W1_2_Stat.html">2.4. Statistical Forecasting in Environmental Sciences</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ML/S1_3_Statistical_Forecasting.html">2.5. (Exercises) Statistical Forecasting</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ML/Week_2_Decision_Trees_Random_Forests_SVMs.html">3. Decision Trees, Random Forests, Support Vector Machines and Environmental Risk Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/Simple_Machine_Learning_Algorithms_for_Classification_Tasks.html">3.1. Simple Machine Learning Algorithms for Classification Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/%28Exercises%29_Support_Vector_Machines.html">3.2. (Exercises) Support Vector Machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/%28Exercises%29_Decision_Trees_and_Random_Forest.html">3.3. (Exercises) Decision Trees and Random Forest</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/%28Exercises%29_Ensemble_Modeling_and_Stacking.html">3.4. (Exercises) Ensemble Modeling and Stacking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/%28Exercises%29_Wildfire_Susceptibility_Mapping.html">3.5. (Exercises) Wildfire Susceptibility Mapping</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ML/Week_3_Dimensionality_Reduction_Clustering.html">4. Unsupervised Learning for Clustering/Dimensionality Reduction and Environmental Complexity</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Jingyan/Chapter4-UnsupervisedLearning.html">4.1. Unsupervised Learning for Clustering and Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ML/S3_1_Dimensionality.html">4.2. (Exercise) Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ML/S3_2_Clustering.html">4.3. (Exercise) Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ML/S3_3_THOR.html">4.4. (Exercise) Ocean Regimes Identification</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">(Part III) Deep Learning for the Geosciences</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../DL/Week_4_Artificial_Neural_Networks.html">5. Artificial Neural Networks and Surrogate Modeling</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">5.1. Introduction to Artificial Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../DL/S4_1_NNs_with_Keras.html">5.2. (Exercise) Artificial Neural Networks with Keras</a></li>
<li class="toctree-l2"><a class="reference internal" href="../DL/S4_2_Physically_informed_parameterization.html">5.3. (Exercise) Physically-Informed Climate Modeling</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../DL/Week_5_Convolutional_NN.html">6. Convolutional Neural Networks and Remote Sensing</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Jingyan/Ch5%20Convolutional%20Neural%20Networks%20%26%20Remote%20Sensing.html">6.1. Convolutional Neural Networks and Remote Sensing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../DL/S5_1_CNNs.html">6.2. (Exercise) Deep Computer Vision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../DL/S5_2_CNN_and_EuroSAT.html">6.3. (Exercise) Land Cover Classification</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../DL/Week_6_Recurrent_NN.html">7. Recurrent Neural Networks and Hydrological Modeling</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="W6_RNN_Summary.html">7.1. Introduction to Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/Neural_Networks_for_Time_Series_Predictions.html">7.2. Neural Networks for Time Series Predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../DL/S6_1_Composing_Music_With_RNNs_CNNs.html">7.3. (Exercise) Composing Music</a></li>
<li class="toctree-l2"><a class="reference internal" href="../DL/S6_2_LSTM.html">7.4. (Exercise) Hydrological Modeling</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">(Part IV) Towards Trustworthy AI</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../DL/W8_XAI.html">8. Explainable Artifical Intelligence and Understanding Predictions</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/S8_XAIsummary.html">8.1. Why do we need machine learning model interpretability?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Frederick/Chapter8_Ex1.html">8.2. (Exercise) XAI on Simple Datasets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Jingyan/ch9generative_uncertainty.html">9. Generative Modeling and Uncertainty Quantification</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FSaranya/W4_ANN.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Saranya/W4_ANN.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Introduction to Artificial Neural Networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-neural-networks">5.1.1. Understanding Neural Networks:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perceptron">5.1.2. Perceptron</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-a-neural-network">5.1.3. Create a Neural Network</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a href="https://colab.research.google.com/github/tbeucler/2023_MLEES_JB/blob/main/ML_EES/Saranya/W4_ANN.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<div class="tex2jax_ignore mathjax_ignore section" id="introduction-to-artificial-neural-networks">
<h1><span class="section-number">5.1. </span>Introduction to Artificial Neural Networks<a class="headerlink" href="#introduction-to-artificial-neural-networks" title="Permalink to this headline">#</a></h1>
<p>This chapter summarizes Chapter 10 of ‚ÄúHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow‚Äù by Aur√©lien G√©ron which introduces the fundamentals of Artificial Neural Networks (ANNs).</p>
<p><strong>Learning Objectives</strong>:</p>
<ol class="arabic simple">
<li><p>Define an artificial neural network</p></li>
<li><p>Understand activation functions</p></li>
<li><p>Understand the steps &amp; best practices to build an artificial neural network</p></li>
<li><p>Know the main hyperparameters defining a neural network‚Äôs architecture</p></li>
<li><p>Know the main hyperparameters controlling the training of a neural network</p></li>
</ol>
<div class="section" id="understanding-neural-networks">
<h2><span class="section-number">5.1.1. </span>Understanding Neural Networks:<a class="headerlink" href="#understanding-neural-networks" title="Permalink to this headline">#</a></h2>
<p><strong>Artificial Neural Networks</strong> (ANNs) are computational models inspired by the human brain. They consist of interconnected nodes (neurons) organized in layers. Information flows through these nodes, undergoing weighted computations and transformations, allowing ANNs to learn patterns and relationships from data, used widely in machine learning tasks.</p>
<blockquote>
<div><p><strong>Neurons</strong>: Neurons are the basic building blocks of ANNs. They receive inputs, perform computations, and produce outputs.</p>
</div></blockquote>
<blockquote>
<div><p><strong>Layers</strong>: ANNs consist of an input layer, one or more hidden layers, and an output layer.</p>
</div></blockquote>
<blockquote>
<div><p><strong>Activation Functions</strong>: Activation functions introduce <strong>non-linearity</strong> to neurons, enabling the network to model complex relationships.</p>
</div></blockquote>
<blockquote>
<div><p><strong>Feed-forward Neural Networks</strong> (FNNs): FNNs pass information in one direction, from input to output. They are used for tasks like classification and regression.</p>
<blockquote>
<div><p>Example: Building an FNN to classify species based on environmental data.</p>
</div></blockquote>
</div></blockquote>
<blockquote>
<div><p><strong>Backpropagation</strong>: Backpropagation is the training algorithm for ANNs. It adjusts the network‚Äôs weights and biases to minimize the error.</p>
<blockquote>
<div><p>Example: Training an ANN to predict air quality based on historical data.</p>
</div></blockquote>
</div></blockquote>
<blockquote>
<div><p><strong>Hyperparameter Tuning</strong>: ANNs have numerous hyperparameters that influence their performance, including the number of layers, neurons per layer, and learning rate.</p>
<blockquote>
<div><p>Example: Experimenting with different network architectures to optimize accuracy in predicting forest fire occurrences.</p>
</div></blockquote>
</div></blockquote>
<blockquote>
<div><p><strong>Overfitting</strong> and <strong>Regularization</strong>: ANNs are susceptible to overfitting, where they memorize training data but perform poorly on new data.</p>
<blockquote>
<div><p>Techniques like dropout and early stopping mitigate overfitting.
Example: Implementing dropout layers to improve the generalization of an ANN for predicting species distribution.</p>
</div></blockquote>
</div></blockquote>
<blockquote>
<div><p><strong>Environmental Applications</strong> üåÑ: ANNs are used in environmental sciences for various tasks, such as weather forecasting, climate modeling, and remote sensing image analysis.</p>
<blockquote>
<div><p>Example: Using ANNs to predict rainfall patterns based on climate data for flood risk assessment.</p>
</div></blockquote>
</div></blockquote>
</div>
<div class="section" id="perceptron">
<h2><span class="section-number">5.1.2. </span>Perceptron<a class="headerlink" href="#perceptron" title="Permalink to this headline">#</a></h2>
<blockquote>
<div><p>A <strong>perceptron</strong> is one of the simplest ANN architectures, used for binary classification tasks. In its simplest form, composed of one input layer and one output layer, a perceptron takes multiple binary inputs, applies weights to these inputs, sums them up, adds a bias term, and then passes the result through an activation function (e.g. step function) to produce an output.</p>
</div></blockquote>
<p>Here‚Äôs a breakdown of the components and the function of a perceptron:</p>
<blockquote>
<div><p><strong>Inputs</strong> (X1, X2, X3, ‚Ä¶): These are the features or inputs to the perceptron. Each input is assigned a weight (W1, W2, W3, ‚Ä¶) which determines its importance in the computation.
<strong>Weights</strong> (W1, W2, W3, ‚Ä¶): Weights are associated with each input and represent the strength of the connection between the input and the perceptron.
<strong>Summation</strong> (Œ£): The weighted sum of the inputs is calculated as follows:</p>
<blockquote>
<div><p>Sum = (X1 * W1) + (X2 * W2) + (X3 * W3) + ‚Ä¶</p>
</div></blockquote>
</div></blockquote>
<blockquote>
<div><p><strong>Bias</strong> (B): A bias term is added to the weighted sum. The bias allows the perceptron to shift its decision boundary.
Sum with Bias = Sum + B<br />
<strong>Activation Function</strong> (e.g., Step function): The result of the summation is passed through an activation function. The most common activation function for a perceptron is the step function. If the result is above a certain threshold, the perceptron outputs a ‚Äú1‚Äù (or ‚ÄúTrue‚Äù); otherwise, it outputs a ‚Äú0‚Äù (or ‚ÄúFalse‚Äù).
<strong>Output</strong> = 1 if (Sum with Bias &gt; Threshold), else 0</p>
</div></blockquote>
<p>Here is an environmental science üåÑ example where a perceptron can be used:</p>
<blockquote>
<div><p>Perceptron for <strong>Species Classification</strong>:
Imagine you‚Äôre working on a project to identify whether a particular bird species is present in a given area based on environmental features like temperature, humidity, and vegetation density.
You have data on the presence (1) or absence (0) of the bird species in different locations.</p>
<blockquote>
<div><p>In this scenario, you can use a perceptron to build a binary classifier. The inputs would be the environmental features (e.g., temperature, humidity, vegetation density), each with its corresponding weight representing its importance in determining bird presence. The perceptron computes the weighted sum of these inputs, adds a bias term, and passes the result through a step function. If the output is 1, it predicts the presence of the bird species; otherwise, it predicts absence.</p>
</div></blockquote>
</div></blockquote>
<p>A single perceptron may have limitations in capturing complex relationships in environmental data, which calls for more complex neural network architectures, such as multi-layer perceptrons (MLPs).</p>
<blockquote>
<div><p><strong>Multilayer Perceptron</strong> (MLP)</p>
<blockquote>
<div><p>The stack of multiple perceptrons, composed of one input layer, one or more hidden layers, and one final output layer.</p>
</div></blockquote>
</div></blockquote>
</div>
<div class="section" id="create-a-neural-network">
<h2><span class="section-number">5.1.3. </span>Create a Neural Network<a class="headerlink" href="#create-a-neural-network" title="Permalink to this headline">#</a></h2>
<p><strong>Building a neural network</strong> in practice involves several steps, from data preparation to model evaluation. Let‚Äôs go through these steps using an example related to environmental science üåÑ: predicting air quality based on meteorological data.</p>
<blockquote>
<div><p>Step 1: <strong>Data Collection and Preprocessing</strong></p>
<blockquote>
<div><p>Data Collection: Gather historical data containing meteorological variables (e.g., temperature, humidity, wind speed) and corresponding air quality measurements (e.g., PM2.5 levels).<br />
Data Preprocessing: Clean the data by handling missing values, outliers, and scaling features to a similar range (e.g., using Min-Max scaling). Split the data into training and testing sets.</p>
</div></blockquote>
</div></blockquote>
<blockquote>
<div><p>Step 2: <strong>Model Selection and Architecture</strong></p>
<blockquote>
<div><p>Choose a Neural Network Architecture: Based on the problem, we select an <em>FNN</em>. Determine the number of input features (based on meteorological data) and the number of output neurons (1 for air quality prediction).
Define the Model: Using a deep learning framework like <code class="docutils literal notranslate"><span class="pre">Keras</span></code>, define the neural network‚Äôs architecture, including the number of hidden layers and neurons per layer, as well as the activation functions.</p>
</div></blockquote>
</div></blockquote>
<p>For simplicity, let‚Äôs create a model with one hidden layer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;tensorflow&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_features</span><span class="p">,)),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Output layer for air quality prediction</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>Step 3: <strong>Compilation</strong></p>
<blockquote>
<div><p>Compile the Model: Specify the loss function (e.g., Mean Squared Error for regression tasks), the optimizer (e.g., Adam or SGD), and evaluation metrics (e.g., Mean Absolute Error).</p>
</div></blockquote>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mean_absolute_error&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>Step 4: <strong>Training</strong></p>
<blockquote>
<div><p>Train the Model: Use the training data to fit the neural network. Specify the number of epochs (iterations over the entire training dataset) and batch size.</p>
</div></blockquote>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>Step 5: <strong>Evaluation</strong></p>
<blockquote>
<div><p>Evaluate the Model: Use the testing data to assess the model‚Äôs performance. Evaluate metrics like Mean Absolute Error (MAE) or Root Mean Squared Error (RMSE) to measure prediction accuracy.</p>
</div></blockquote>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_loss</span><span class="p">,</span> <span class="n">test_mae</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test MAE: </span><span class="si">{</span><span class="n">test_mae</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>Step 6: <strong>Hyperparameter Tuning</strong></p>
<blockquote>
<div><p><strong>Hyperparameters defining the network architecture</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Number of Layers</strong>: Defines the depth of the network.</p></li>
<li><p><strong>Number of Neurons per Layer</strong>: Determines the width of each layer.</p></li>
<li><p><strong>Activation Functions</strong>: Specifies the functions used to introduce non-linearity.</p></li>
<li><p><strong>Architecture-Specific Parameters</strong>: Parameters unique to specific network types.
<strong>Hyperparameters controlling the training process</strong>:</p></li>
<li><p><strong>Learning Rate</strong>: Governs the step size in updating weights during training.</p></li>
<li><p><strong>Batch Size</strong>: Specifies the number of samples processed before updating model parameters.</p></li>
<li><p><strong>Optimizer</strong>: Algorithms adjusting weights during training (e.g., SGD, Adam, RMSprop).</p></li>
<li><p><strong>Regularization Techniques</strong>: Methods to prevent overfitting (e.g., dropout rates, L1/L2 regularization).</p></li>
<li><p><strong>Initialization Schemes</strong>: Initial values for weights and biases.</p></li>
<li><p><strong>Early Stopping</strong>: Criterion to stop training based on validation performance.</p></li>
<li><p><strong>Training Epochs</strong>: Number of iterations through the entire dataset during training.</p></li>
</ol>
</div></blockquote>
</div></blockquote>
<blockquote>
<div><p>Step 7: <strong>Deployment</strong></p>
<blockquote>
<div><p>Deploy the Model: Once satisfied with the model‚Äôs performance, deploy it in a production environment. It can be used to make real-time air quality predictions based on incoming meteorological data.</p>
</div></blockquote>
</div></blockquote>
<p>In this example, we‚Äôve built a simple neural network for air quality prediction. In practice, you can enhance the model by incorporating more complex architectures (e.g., convolutional neural networks for image-based environmental data) and larger datasets. Neural networks in environmental science can be applied to various tasks, such as predicting pollutants, forecasting weather patterns, or modeling climate phenomena.</p>
<blockquote>
<div><blockquote>
<div><p><em>Tips and Tricks</em> üí°</p>
</div></blockquote>
</div></blockquote>
<ul class="simple">
<li><p><strong>How many hidden layers?</strong></p></li>
</ul>
<blockquote>
<div><p>The choice of the number of hidden layers in a neural network depends on the complexity of the problem you‚Äôre addressing. You can often <em>start with a few hidden layers and increase their number as needed</em>, while more complex tasks may involve <em>deep networks</em> or <em>transfer learning from pretrained models</em>.</p>
<blockquote>
<div><p><strong>Single Hidden Layer</strong>: For many problems, starting with a single hidden layer can yield reasonable results. Such a network, theoretically, can model even complex functions when it has a sufficient number of neurons.
Benefits of <strong>Deep Networks</strong>: In more complex problems, deep neural networks (DNNs) with multiple hidden layers are highly parameter-efficient. They can model complex functions using exponentially fewer neurons than shallow networks. This efficiency enables deep networks to achieve better performance with the same amount of training data.
<strong>Hierarchical Learning</strong>: DNNs take advantage of the hierarchical nature of real-world data. Lower layers capture low-level structures (e.g., line segments), intermediate layers combine these to model intermediate-level structures (e.g., shapes), and the highest layers model high-level structures (e.g., faces). This hierarchical architecture aids convergence and generalization.
<strong>Transfer Learning</strong>: Deep networks also enable transfer learning. When you want to train a new network for a related task, you can reuse the lower layers of a pre-trained network. This approach accelerates learning by building upon already learned low-level structures.
<strong>Network Complexity</strong>: Start with one or two hidden layers for many problems. For instance, you can achieve high accuracy on tasks like MNIST with one or two hidden layers. As problems become more complex, you can increase the number of hidden layers. Very complex tasks, like large image classification or speech recognition, may require networks with many layers.
<strong>Pretrained Models</strong>: For very complex tasks, it‚Äôs common to use pretrained state-of-the-art networks and fine-tune them for the specific problem. This approach significantly speeds up training and requires less data.</p>
</div></blockquote>
</div></blockquote>
<ul class="simple">
<li><p><strong>How many neurons in the hidden layers?</strong></p></li>
</ul>
<blockquote>
<div><p>The number of neurons in hidden layers should be chosen based on the specific requirements of your task. Traditional pyramid-style sizing is less common, and <em>using the same number of neurons in all hidden layers</em> is often an effective and simpler approach. Consider the dataset and employ techniques to avoid overfitting.</p>
<blockquote>
<div><p><strong>Input and Output Neurons</strong>: The number of neurons in the input and output layers depends on the specific requirements of your task. For example, the MNIST dataset, with 28x28 pixel images, has 784 input neurons and 10 output neurons for digit classification.<br />
<strong>Hidden Layer Sizing</strong>: Traditionally, hidden layers were often structured as a pyramid, with a decreasing number of neurons in each layer. The idea was that low-level features could combine into fewer high-level features. For MNIST, a neural network might have 3 hidden layers, with sizes like 300, 200, and 100.<br />
<strong>Simplified Approach</strong>: The practice of designing hidden layers as a pyramid has become less common. Using the same number of neurons in all hidden layers has been found to perform equally well or even better in most cases. This approach simplifies hyperparameter tuning.<br />
<strong>First Layer Size</strong>: In some cases, it may be beneficial to make the first hidden layer larger than the subsequent layers, depending on the dataset.<br />
<strong>Avoiding Overfitting</strong>: You can gradually increase the number of neurons until the network starts overfitting. In practice, it‚Äôs often simpler to choose a model with more layers and neurons than needed and then use techniques like early stopping and regularization to prevent overfitting.<br />
<strong>‚ÄúStretch Pants‚Äù Approach</strong>: This approach, often referred to as ‚Äústretch pants,‚Äù involves starting with a larger model and allowing it to shrink down to the right size during training.</p>
</div></blockquote>
</div></blockquote>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Saranya"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../DL/Week_4_Artificial_Neural_Networks.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Artificial Neural Networks and Surrogate Modeling</p>
      </div>
    </a>
    <a class="right-next"
       href="../DL/S4_1_NNs_with_Keras.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5.2. </span>(Exercise) Artificial Neural Networks with Keras</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-neural-networks">5.1.1. Understanding Neural Networks:</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perceptron">5.1.2. Perceptron</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-a-neural-network">5.1.3. Create a Neural Network</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Tom Beucler, Milton Gomez, Frederick Iat-Hin Tam, Jingyan Yu, Saranya Ganesh S
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      ¬© Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>